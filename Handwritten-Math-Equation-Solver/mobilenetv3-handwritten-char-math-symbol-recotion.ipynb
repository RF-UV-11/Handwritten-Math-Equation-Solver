{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7830344,"sourceType":"datasetVersion","datasetId":4588967}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\ndef rename_and_copy_folders(root_dir, dest_dir):\n    # Define mapping for renaming\n    mapping = {\n        \"10\": \"A\", \"11\": \"B\", \"12\": \"C\", \"13\": \"D\", \"14\": \"E\", \"15\": \"F\", \n        \"16\": \"G\", \"17\": \"H\", \"18\": \"I\", \"19\": \"J\", \"20\": \"K\", \"21\": \"L\", \n        \"22\": \"M\", \"23\": \"N\", \"24\": \"O\", \"25\": \"P\", \"26\": \"Q\", \"27\": \"R\", \n        \"28\": \"S\", \"29\": \"T\", \"30\": \"U\", \"31\": \"V\", \"32\": \"W\", \"33\": \"X\", \n        \"34\": \"Y\", \"35\": \"Z\", \"36\": \"a\", \"37\": \"b\", \"38\": \"c\", \"39\": \"d\", \n        \"40\": \"e\", \"41\": \"f\", \"42\": \"g\", \"43\": \"h\", \"44\": \"i\", \"45\": \"j\", \n        \"46\": \"k\", \"47\": \"l\", \"48\": \"m\", \"49\": \"n\", \"50\": \"o\", \"51\": \"p\", \n        \"52\": \"q\", \"53\": \"r\", \"54\": \"s\", \"55\": \"t\", \"56\": \"u\", \"57\": \"v\", \n        \"58\": \"w\", \"59\": \"x\", \"60\": \"y\", \"61\": \"z\",\n        'x_sampled': '*', \n    '÷_sampled': '÷', \n    '(_sampled': '(', \n    ')_sampled': ')', \n    '+_sampled': '+', \n    '-_sampled': '-'\n    }\n\n    for subdir, dirs, files in os.walk(root_dir):\n        # Get the name of the current directory\n        dir_name = os.path.basename(subdir)\n        # Get the new name from mapping\n        new_name = mapping.get(dir_name, dir_name)\n        # Construct the new directory path\n        new_dir_path = os.path.join(dest_dir, new_name)\n        # Create the new directory\n        os.makedirs(new_dir_path, exist_ok=True)\n        # Copy files to the new directory\n        for file in files:\n            src_file_path = os.path.join(subdir, file)\n            dest_file_path = os.path.join(new_dir_path, file)\n            shutil.copyfile(src_file_path, dest_file_path)\n\n# Kaggle specific paths\nroot_directory = \"/kaggle/input/balanced-emnist-maths-symbol-dataset/\"\ndestination_directory = \"/kaggle/working/renamed_dataset/\"\nrename_and_copy_folders(root_directory, destination_directory)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T07:06:35.637019Z","iopub.execute_input":"2024-03-13T07:06:35.637409Z","iopub.status.idle":"2024-03-13T07:12:20.582249Z","shell.execute_reply.started":"2024-03-13T07:06:35.637367Z","shell.execute_reply":"2024-03-13T07:12:20.581353Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV3Small\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n# Define the root directory of your dataset\ndataset_dir = \"/kaggle/working/renamed_dataset\"\n\n# Define the image size\nimg_height, img_width = 224, 224\n\n# Prepare data\ndatagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_generator = datagen.flow_from_directory(\n    dataset_dir,\n    target_size=(img_height, img_width),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training')\n\nval_generator = datagen.flow_from_directory(\n    dataset_dir,\n    target_size=(img_height, img_width),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation')\n\n# Define the MobileNetV3 model\nbase_model = MobileNetV3Small(input_shape=(img_height, img_width, 3),\n                              weights='imagenet',\n                              include_top=False)\n\nx = GlobalAveragePooling2D()(base_model.output)\noutput = Dense(68, activation='softmax')(x)  # 68 classes: 0-9, A-Z, a-z, (,), -, +, *, /\n\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Compile the model\nmodel.compile(optimizer=Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(train_generator, epochs=10, validation_data=val_generator)\n\n# Save the trained model\nmodel.save(\"/kaggle/working/mobilenetv3_symbol_classifier.h5\")\n\n# Function to predict class for a single image\ndef predict_class(image_path, model):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize\n    prediction = model.predict(img_array)\n    predicted_class_index = np.argmax(prediction)\n    class_labels = sorted(train_generator.class_indices.keys())\n    predicted_class = class_labels[predicted_class_index]\n    return predicted_class\n\n# Example usage: Predicting class for a single image\nimage_path = \"/kaggle/working/renamed_dataset/0/643251.png\"  # Adjust with your image path\npredicted_class = predict_class(image_path, model)\nprint(\"Predicted class:\", predicted_class)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:35:19.709184Z","iopub.execute_input":"2024-03-13T08:35:19.710095Z","iopub.status.idle":"2024-03-13T08:52:37.549468Z","shell.execute_reply.started":"2024-03-13T08:35:19.710062Z","shell.execute_reply":"2024-03-13T08:52:37.548432Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 60860 images belonging to 68 classes.\nFound 15164 images belonging to 68 classes.\nEpoch 1/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 77ms/step - accuracy: 0.6309 - loss: 1.1406 - val_accuracy: 0.0148 - val_loss: 8.6852\nEpoch 2/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 46ms/step - accuracy: 0.7705 - loss: 0.5520 - val_accuracy: 0.0292 - val_loss: 6.7714\nEpoch 3/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 46ms/step - accuracy: 0.7900 - loss: 0.4946 - val_accuracy: 0.3599 - val_loss: 2.5779\nEpoch 4/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 47ms/step - accuracy: 0.8015 - loss: 0.4579 - val_accuracy: 0.1600 - val_loss: 3.7245\nEpoch 5/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 46ms/step - accuracy: 0.8088 - loss: 0.4402 - val_accuracy: 0.5681 - val_loss: 1.4864\nEpoch 6/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 46ms/step - accuracy: 0.8101 - loss: 0.4264 - val_accuracy: 0.5983 - val_loss: 1.2299\nEpoch 7/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 45ms/step - accuracy: 0.8199 - loss: 0.4037 - val_accuracy: 0.3603 - val_loss: 2.5190\nEpoch 8/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 46ms/step - accuracy: 0.8290 - loss: 0.3849 - val_accuracy: 0.3976 - val_loss: 3.1194\nEpoch 9/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 47ms/step - accuracy: 0.8352 - loss: 0.3704 - val_accuracy: 0.4846 - val_loss: 1.7474\nEpoch 10/10\n\u001b[1m1902/1902\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 47ms/step - accuracy: 0.8445 - loss: 0.3471 - val_accuracy: 0.6914 - val_loss: 0.8537\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\nPredicted class: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_class(image_path, model):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize\n    prediction = model.predict(img_array)\n    predicted_class_index = np.argmax(prediction)\n    class_labels = sorted(train_generator.class_indices.keys())\n    predicted_class = class_labels[predicted_class_index]\n    return predicted_class\n\n# Example usage: Predicting class for a single image\nimage_path = \"/kaggle/working/renamed_dataset/v/239328.png\"  # Adjust with your image path\npredicted_class = predict_class(image_path, model)\nprint(\"Predicted class:\", predicted_class)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T08:55:18.692249Z","iopub.execute_input":"2024-03-13T08:55:18.692934Z","iopub.status.idle":"2024-03-13T08:55:18.768752Z","shell.execute_reply.started":"2024-03-13T08:55:18.692903Z","shell.execute_reply":"2024-03-13T08:55:18.767848Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nPredicted class: V\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}